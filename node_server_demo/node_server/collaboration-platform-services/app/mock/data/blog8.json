{
  "blog_id": "blog_mock_8",
  "title": "Introduction to Vert.x",
  "author": null,
  "content": "<p><span style=\"color: #800080;\"><strong>Vert.x</strong></span> is an open source tool kit to build reactive applications on JVM. This project was started by Tim Fox as Node.x in 2011 when he was working for VMware. Since then major developments are going on in Vert.x space and there are many committers to the Vert.x github branch. In May 2014 Vert.x won the award for \"Most Innovative Java Technology\" at the JAX Innovation awards. The latest version Vert.x 3.0 was released in the month of June 2015. This is considered to be the major release for Vert.x as there have been many changes in the framework code and support for many different tools and frameworks have been added. <a href=\"https://vista-mindtree.cloudapp.net/coe_open/wp-content/uploads/2015/08/vertx-intro.png\"><img class=\"aligncenter wp-image-5248 size-large\" src=\"https://vista-mindtree.cloudapp.net/coe_open/wp-content/uploads/2015/08/vertx-intro-1024x302.png\" alt=\"vertx-intro\" width=\"1000\" height=\"294\" /></a> Let us look at the problems that led to the development of Vert.x Traditional blocking approach – In traditional applications the style of execution is a blocking one. What this means is, when you call a certain function which does a specific job the caller of the function has to wait for the called function to return with the results. This sounds ok and is not a problem. The problem starts when the function you are calling does a CPU intensive I/O operation, like a file or database operation, which can be time consuming. When this operation is in progress the caller of the function is doing nothing than to wait for the results. In other words the caller is BLOCKED. Such kind of time consuming I/O operations are termed blocking operations. One such example of blocking operation can be a tomcat container listening to HTTP requests. Say suppose the <strong><em>maxThread ***count is set to 200. This means that at a given point of time the tomcat container can serve only 200 requests. The 201th request has to wait in a queue until a thread is released back into the thread pool. If there is database operation involved as part of processing the request then many threads waste their time in waiting for the results to be fetched from database rather than handling new incoming requests. To visualize a real world scenario of a blocking operation let’s look at this example. Say suppose you are going for a movie with your family in a car. So you drive to the movie theater, park the car, buy your tickets and watch the movie for 3 hours. During these three hours of the movie the car is standing idle in the parking and you are paying parking fees for the car which is doing nothing. <a href=\"https://vista-mindtree.cloudapp.net/coe_open/wp-content/uploads/2015/08/cars-eg.png\"><img class=\"aligncenter wp-image-5245 size-full\" src=\"https://vista-mindtree.cloudapp.net/coe_open/wp-content/uploads/2015/08/cars-eg.png\" alt=\"cars-eg\" width=\"652\" height=\"239\" /></a> The real power of a car comes only when it is running. So this is bad utilization of the resource (car). So what do you think would have been a better approach? In this case the optimum utilization of car can be possible when you are hiring a taxi. The taxi drops you to theater and goes to serve some other customer(s) when you are in a movie. The taxi is never stopping and is always on a move. Coming back to the main problem, if we can think of the processing thread as a car, the thread is idle when there is a blocking I/O operation in progress and this leads to underutilization of the processing thread just like our car in the parking. To solve this issue we have to come up with an idea similar to that of a taxi which serves the customers at all times and is never kept idle. Such kind of problems are solved by a programming paradigm called ***REACTIVE</em></strong> <strong><em>PROGRAMMING.</em></strong> Reactive programming essentially means that your application should be, \n*   Event driven – react to various events\n*   Fault tolerant – react to failures\n*   Scalable – react to loads\n*   Responsive – react to users Vert.x follows the reactive approach in solving problems. So your application is now full of events and callbacks (or event handlers). As Vert.x is reactive the applications that you implement using Vert.x are high performing and pretty fast as the unnecessary thread waits are minimized. Let us look at some of the cool features of Vert.x,</p>\n\n<ul>\n<li><strong>Lightweight</strong> – Vert.x is a lightweight library (600+ kbytes). The only dependencies it has is on the embedded netty server, hazelcast for cluster management, Jackson for JSON handling</li>\n<li><strong>Distributed</strong> - Vert.x is distributed. This means your application can be deployed on multiple machines at once.</li>\n<li><strong>Scalable</strong> – Applications can be scaled horizontally. Whenever the load increases you can add in new nodes and whenever load decreases you can dispose some nodes. This way it is cost effective from a hardware utilization standpoint.</li>\n<li><strong>Polyglot</strong> – You can write Vert.x applications in 9 different languages. Isn’t this cool? You can use the language which suits you or fits the problem at hand. The languages that are currently supported (as of Vert.x 3.0) are Java, JavaScript, Groovy, JRuby, Jython, Clojure, Scala, PHP and Ceylon.</li>\n<li><strong>Event driven</strong> – As Vert.x follows a reactive approach the code you write will be full of events and event listeners. Vert.x executes the code with the help of event-loops which are constantly listening for incoming events.</li>\n<li><strong>Modular</strong> – Vert.x has a concept of Verticle which is a basic execution unit in Vert.x. All the execution code goes into separate Verticles. This way you are forced to write modular code with clear boundaries rather than creating modules with overlapping boundaries.   </li>\n</ul>\n\n<p><strong><span style=\"font-size: 18pt;\">Components of a Vert.x environment</span></strong> <strong><span style=\"font-size: 12pt;\">Verticle</span></strong> – This is the basic execution unit in Vert.x. All your programming logic and surrounding code goes in this file. Verticles can be written in any language (mentioned above). One more important thing to know about Vert.x is that it is Single threaded. Let us understand what this means. Vert.x calculates the number of CPU cores present on the execution machine and starts those many number of threads. So a 4-core machine will have four event-loop threads running. Each of this event-loop is assigned a set of Verticles to be executed on those event-loops. So for a Vert.x application with four Verticles running on a 4-core machine, four event-loop threads are started by Vert.x. Now each event loop is assigned a Verticle as shown in the diagram below, <a href=\"https://vista-mindtree.cloudapp.net/coe_open/wp-content/uploads/2015/08/event-loop.jpg\"><img class=\"aligncenter wp-image-5247 size-full\" src=\"https://vista-mindtree.cloudapp.net/coe_open/wp-content/uploads/2015/08/event-loop.jpg\" alt=\"event-loop\" width=\"627\" height=\"330\" /></a>   The Verticle code is executed by the event-loop thread which is assigned to it and no one else. This way there is no possibility of a race condition to occur as the Verticle code is executed by one and only one thread at any given instance of time. The different Verticles communicate via message passing which is inspired by the Actor model. As the Verticle code is running on an event-loop we should ensure that the tasks we are doing on the Verticle are non-blocking tasks. But then, every application has some functionality present which makes use of database or file system which is considered as BLOCKING. For such tasks Vert.x has a concept of <strong>Worker Verticle</strong> which runs on a thread from the background thread pool and not on the event-loop thread. Like normal Verticles Worker Verticles are never executed by more than one thread at a given point of time. Hence the Single Threaded Model still holds good. <span style=\"font-size: 12pt;\"><strong>Event bus</strong></span> – Event bus forms the nervous system of the Vert.x application. All the Verticles communicate via the event bus by passing messages in JSON or plain text format. The JSON messages can be serialized and de-serialized in the Verticles by using the Vert.x libraries. The communication between Verticles can be of three types, \n1.  Point to point – A message is sent from one Verticle to another and sender does not expect a reply from the receiver.\n2.  Request/Response - A message is sent from one Verticle to another and sender expects a response from the receiver.\n3.  Publish/Subscribe - A message is published to a topic on the event bus. All the Verticles that are subscribing to that topic will receive the messages. The Publisher is unaware of the subscribers. As we said before that Vert.x is distributed the reason being that event bus is also distributed. Event bus can span multiple Vert.x nodes running in a cluster. Vert.x doesn’t require a monolithic application server (like tomcat, Jboss etc.) it runs as a jvm process. It clusters with another instance(s) running in the same network by using multicast discovery. As Vert.x is distributed and provides Event bus out of the box it becomes an ideal choice for implementing micro services. Event bus can not only span several Vert.x instances in the server zone but can also span all the way to client browsers. There is a Vert.x SockJS Adapter that helps connecting the Vert.x event bus with that of a client running on browser. The client can connect to the event bus by using a SockJS library which is a high level abstraction of web-socket implementation. This connection helps us in developing real time applications in which the server pushes the data to the client rather than the client requesting for it. The API used to communicate through the event bus on the client is same as the one used on the server side. The components of Vert.x are shown in the figure below. It is a clustered Vert.x application with Verticles running on different Vert.x nodes and the event bus spanning all the way to the client browsers.</p>\n\n<p><a href=\"https://vista-mindtree.cloudapp.net/coe_open/wp-content/uploads/2015/08/eventbus.png\"><img class=\"aligncenter wp-image-5246 size-full\" src=\"https://vista-mindtree.cloudapp.net/coe_open/wp-content/uploads/2015/08/eventbus.png\" alt=\"eventbus\" width=\"819\" height=\"463\" /></a>   So in conclusion let me summarize the topic for you. \n*   With Vert.x you can write apps that are composed of components that can run or live anywhere. No application server is needed.\n*   Polyglot – Use the language of your choice\n*   Simple concurrency – No multithreading problems\n*   Verticles – a library of Lego bricks to build apps with   I would encourage everyone to try out this exciting technology which is grabbing more eye-balls day by day.  </p>\n",
  "status": "PUBLISHED",
  "viewed_by": [],
  "tags": ["vertx", "polyglot"],
  "liked_by": [],
  "comments": [],
  "dateOfPublishing": "2016-06-17T16:25:24.306Z"
}